---
title: "Webアプリのインフラエンジニアがデータ基盤を構築するので勉強してみた"
emoji: "🗄️"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["AWS", "DataEngineering", "Redshift", "Athena", "dbt"]
published: false
publication_name: finatext
---

## Webアプリを作ってきたインフラエンジニアがデータ基盤に挑戦するときの道しるべ

これは何？
インフラエンジニアがAIと一緒に学びながらまとめた、データ基盤構築のナレッジです。
「EC2やRDS、ALBなど触れてきましたが、データ基盤には触れていなかったので、データエンジニアリングってどうやるの？」という疑問から始まった学習記録を、共有できる形にしました。

想定読者:

- Webアプリのインフラは分かるけど、データ基盤は初めて
- RDSとRedshiftって何が違うの？OLTP vs OLAPって何？
- データレイクとデータウェアハウスってどう使い分けるの？

前提知識:

- AWS基礎（EC2, ALB, RDS, S3くらい触ったことある）
- SQL基礎（SELECT文書ける）

---

## 目次

1. [概要](#1-概要)
2. [前提知識](#2-前提知識)
3. [実際に作るとなるとどんなインフラ構成になるか](#3-実際に作るとなるとどんなインフラ構成になるか)
   - [パターンA: 小規模構成](#パターンa-小規模構成-数gb月次レポート程度)
   - [パターンB: AWS完結型DWH構成](#パターンb-aws完結型dwh構成-redshift中心)
   - [パターンC: SaaS型DWH構成](#パターンc-saas型dwh構成-snowflakedatabricks中心)
4. [データベースの選定](#4-データベースの選定)
5. [学習してみて感じたこと](#5-学習してみて感じたこと)
6. [まとめ](#6-まとめ)

---

## 1. 概要

### データ基盤とは何か

データ基盤（Data Platform）とは、企業が持つ様々なデータを収集・保存・変換・分析・活用するための統合的なインフラストラクチャです。インフラエンジニアがこれまで扱ってきたWebアプリケーションのインフラ（EC2, ALB, RDS）とは異なり、データ基盤は「大量のデータを効率的に処理し、ビジネス価値を生み出すための分析環境」を提供します。

### なぜデータ基盤が必要なのか

従来のWebアプリケーション用のデータベース（RDS, Aurora）は、トランザクション処理に最適化されています。しかし、以下のような分析ニーズには適していないです：

- 数年分の売上データを集計して傾向を分析したい
- 複数のシステムからデータを統合して全社的なレポートを作成したい
- 機械学習モデルを使って予測分析を行いたい

こうしたニーズに応えるために、分析専用のデータ基盤が必要になります。

### 本記事で学べること

- データ基盤の全体像: OLTP vs OLAP、データレイク vs データウェアハウス
- インフラ構成パターン: 小規模（Lambda + S3 + Athena）、AWS完結型（Glue + Redshift + dbt）、SaaS型（Kinesis + Databricks/Snowflake）
- データベース選定: RDS、Aurora、Athena、Redshift の特徴と使い分け
- 行指向vs列指向ストレージ: データ量とクエリパターンに応じた選択基準

---

## 2. 前提知識

この記事は、EC2やRDSなどWebアプリケーションのインフラは触ってきたけど、データ基盤は初めて、というインフラエンジニアを対象としています。以下のような知識があれば読み進められます：

### AWS基本サービス

- EC2 : 仮想サーバーの起動・管理
- S3 : オブジェクトストレージの基本操作
- VPC : ネットワーク構成の基礎
- IAM : ロールとポリシーによる権限管理

### SQL基礎

- 基本クエリ: `SELECT`, `WHERE`, `ORDER BY`, `GROUP BY`
- テーブル結合: `JOIN` (INNER, LEFT, RIGHT)
- 集計関数: `COUNT`, `SUM`, `AVG`, `MAX`, `MIN`

---

## 3. 実際に作るとなるとどんなインフラ構成になるか

「データ基盤を構築してください」って言われても、データ量やコストによって全然違う構成になります。ここでは、AWSを使った代表的な3パターン（小・中・大規模）を調べました。自分のプロジェクトがどのパターンに当てはまるか考えながら読んでみてください。

---

### パターンA: 小規模構成 (〜数GB、月次レポート程度)

#### 対象

- 学習目的、PoC（概念実証）
- スタートアップや小規模プロジェクト
- 初期コストを抑えたい場合

#### 構成図

```
[データソース]
   (RDS, CSV, API)
        |
        v
  [AWS Lambda]
   (データ収集・軽量な変換)
        |
        v
   [Amazon S3]
   (データレイク)
   ├── raw/        # 生データ(Bronze層)
   └── processed/  #変換後データ(Silver層)
        |
        v
  [AWS Glue Data Catalog]
   (テーブル定義・メタデータ管理)
        |
        v
  [Amazon Athena]
   (SQLでアドホッククエリ)
        |
        v
[QuickSight / Metabase]
   (BIツールで可視化)
```

#### 特徴

1. サーバーレス中心
   - サーバー管理不要、運用負荷が低い
   - Lambda: データ収集、軽量な変換処理
   - Glue Data Catalog: テーブル定義の管理
   - Athena: S3上のデータに対してSQLクエリを実行

2. 従量課金
   - 初期コスト不要、使った分だけ課金
   - スモールスタートに最適

3. 制約
   - 複雑な変換処理には不向き
   - Lambda: メモリ10GB、実行時間15分まで
   - Athena: クエリのたびにS3をスキャン
      - データ量に応じてコスト増）

#### コスト

| サービス | 何に課金されるか | どうやってコスト抑えるか |
|---------|---------|---------------------|
| S3 | 保存してるデータ量 | 古いデータはGlacierに自動移行。ライフサイクルポリシー設定すると便利 |
| Glue Data Catalog | メタデータオブジェクト数 | 100万オブジェクトまで無料。普通は課金されない |
| Athena | SQLでスキャンしたデータ量 | パーティション切らないと大量にスキャンされてコストが急増する。必ず設定すべき |
| Lambda | 実行時間とメモリ | メモリは必要最小限に。バッチ処理でまとめて実行するとコスト減る |
| QuickSight | ユーザー数 | Readerライセンスを使うと安い |

ポイント:

- Lambda + S3 + Glue Data Catalog + Athena でサーバーレスなパイプラインが作れます
- Glue Data Catalogはテーブル定義を管理
- dt=YYYY-MM-DD みたいに日付で切るといったパーティション設計が大事です
- Terraformでインフラをコード管理するのが定石です

#### 参考リンク

- [Athenaの使い方と料金の仕組み](https://aws.amazon.com/jp/athena/)
- [Athenaのパーティション活用](https://docs.aws.amazon.com/ja_jp/athena/latest/ug/partitions.html)
- [Athena関連記事](https://qiita.com/tags/athena)
- [S3上のデータをAWS Athena/Glue で読み取る](https://qiita.com/siwa/items/86a5323094795eb55d2a)

---

### パターンB: AWS完結型DWH構成 (Redshift中心)

#### 対象

- AWSエコシステムで完結させたいデータ分析基盤
- 既にAWSを活用している、またはAWSに統一したい組織
- データ量：数十GB〜数十TB
- 日次バッチ処理、定期的なBIレポート作成

#### 構成図

```
[データソース]
  (RDS, API, ログ)
        |
        v
   [AWS Glue] ← ①抽出: RDS→S3
  (ETLジョブ - Spark)
        |
        v
   [Amazon S3]
   (データレイク)
   ├── raw/        # 生データ(Bronze層)
   |       ↓
   |   [AWS Glue] ← ②軽微な変換: CSV→Parquet、型変換
   |       ↓
   ├── staging/    # 中間データ(Silver層)
   |       ↓
   |   [AWS Glue] ← ③ロード: S3→Redshift
   |       ↓
   └── warehouse/  # 分析用データ(Gold層)
        |
        v
  [Amazon Redshift]
  (データウェアハウス)
        |
        v
     [dbt] ← ④DWH内での変換: SQL (JOIN、集計、ビジネスロジック)
        |
        v
  [Redshift: Martテーブル]
        |
        v
[Tableau / Looker / QuickSight]
  (BIツール)
```

注: Glue は「データレイクへの投入と整形」、dbt は「DWH内での変換」を担当

#### 特徴

1. Redshift: データウェアハウス
   - 列指向ストレージ: 集計クエリが高速
   - MPP (Massively Parallel Processing): 並列処理で大量データを処理
   - 数百GB〜数TBのデータに最適

2. AWS Glue: マネージドETL
   - Sparkベース: 複雑なデータ変換が可能
   - Data Catalog: メタデータ管理（テーブル定義、スキーマ）
   - サーバーレス: インフラ管理不要

3. dbt (data build tool): SQLベースの変換
   - モダンデータスタックの標準ツール
   - バージョン管理、テスト、ドキュメント生成が可能
   - SQLが書ければ使える（学習コスト低）

4. データレイヤー分け
   - Raw層（Bronze）: 生データ（変更不可、監査証跡）
   - Staging層（Silver）: 軽微な変換後のデータ
   - Warehouse/Mart層（Gold）: ビジネスロジックを適用した分析用データ

#### コスト

| サービス | 何に課金されるか | どうやってコスト抑えるか |
|---------|---------|---------------------|
| Redshift | ノード数 × サイズ × 稼働時間 | リザーブドインスタンス買うと最大75%オフ。使わない時間は一時停止するとコストが削減できる |
| AWS Glue | Sparkの実行時間 | 増分処理にして全データ処理しない。ワーカー数も必要最小限に |
| S3 | データ量 | 初期数日間だけ参照され、その後は保管だけされるデータはS3 Glacierに移行するなどライフサイクルポリシー設定を行う |

ポイント:

- Glue ETLでPySparkを書きます
- Redshift の DISTKEY と SORTKEY がパフォーマンスに直結します
- dbt は SQLでデータ変換を書けるから、アナリストも参加しやすい
- Raw → Staging → Mart という段階的なデータ変換が定石

#### 参考リンク

- [dbt入門](https://qiita.com/shun198/items/4e26f776c67c06e55a95)
- [モダンデータスタックとは](https://zenn.dev/rwcolinpeng/articles/9b8040aa689556)
- [Redshiftベストプラクティス](https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/best-practices.html)
- [Redshift関連記事](https://dev.classmethod.jp/tags/amazon-redshift/)

---

### パターンC: SaaS型DWH構成 (Snowflake/Databricks中心)

#### 対象

- 運用負荷を極限まで下げたい組織（サーバー管理、チューニング作業を最小化）
- 自動スケーリング・自動チューニングが必要
- 大規模データ（数TB〜ペタバイト級）の処理
- 複数のチーム・部門で独立したコンピュートリソースを使いたい
- リアルタイム処理や高度な機械学習モデルの活用
- マルチクラウド戦略やベンダーロックイン回避を考慮している組織

#### 構成図

```
[データソース]
  (Kafka, Kinesis, RDS CDC)
        |
        v
[Amazon Kinesis / MSK]
  (ストリーミングデータ収集)
        |
        v
[AWS Glue / Spark on EMR]
  (リアルタイムETL)
        |
        v
   [Amazon S3]
  (Delta Lake / Apache Iceberg)
   ├── bronze/  # 生データ
   ├── silver/  # クレンジング済みデータ
   └── gold/    # 集約済みデータ
        |
        v
[Snowflake / Databricks]
  (統合分析プラットフォーム)
        |
        +--------+--------+
        |                 |
        v                 v
  [BIツール]      [SageMaker / MLflow]
                   (機械学習)
```

#### 特徴

1. ストリーミング処理
   - Kinesis Data Streams: AWSマネージド、シンプルな構成
   - Amazon MSK (Managed Streaming for Kafka): Kafkaのマネージドサービス
   - リアルタイムでデータを収集・処理

2. トランザクショナルなデータレイク
   - Delta Lake: Databricks開発、ACID トランザクション対応
   - Apache Iceberg: Netflixが開発、テーブルフォーマットの標準化
   - データレイクでUPDATE, DELETE, MERGEが可能に

3. Snowflake / Databricks
   - スケーラビリティが高い
   - マルチクラウド対応
   - コンピュートとストレージが分離しているので独立してスケール可能

4. 機械学習統合
   - SageMaker: AWSのマネージドML環境
   - Databricks ML: Sparkと統合されたML環境、MLflow対応

#### コスト

| サービス | 何に課金されるか | どうやってコスト抑えるか |
|---------|---------|---------------------|
| Kinesis Data Streams | シャード数 × 時間 | オンデマンドモード使うと自動でスケールしてくれる。シャード数は必要最小限に |
| Amazon MSK | Kafkaブローカー数 × サイズ | ストレージ自動スケールONにする |
| Snowflake | ウェアハウス稼働時間 + データ量 | 自動停止必ず設定する。アイドル時間設定しないと継続的に課金される |
| Databricks | DBU × 稼働時間 + EC2コスト | 自動終了設定必須。スポットインスタンス使うと最大90%オフ |
| EMR | EC2インスタンス × 時間 | スポットインスタンス使う。ジョブ終わったらクラスター消す |

ポイント:

- Kinesis でリアルタイムにデータを流す
- Delta Lake を使うとS3でもUPDATE/DELETE/MERGEができる
- Snowflake: SQLファーストのデータウェアハウス、BIツール連携が強い（詳細はPart2で）
- Databricks: Spark + ML統合、Notebookで試行錯誤しやすい（詳細はPart2で）
- ストリーミング処理はチェックポイント管理が大事

#### 参考リンク

- [【AWS入門】リアルタイムデータ処理の要！Amazon Kinesis Data Streamsを徹底解説](https://nakaterux.hatenablog.com/entry/2025/06/13/205143/)
- [Delta Lakeとは何か](https://qiita.com/taka_yayoi/items/07c9396809edbf2699b6)
- [Databricks のチュートリアルを始める](https://docs.databricks.com/gcp/ja/getting-started/)
- [Snowflakeで始めるData Lake - Apache Icebergの基本と活用法 -](https://zenn.dev/kokisato/articles/419f4328b13dd5)
- [入門者向けAmazon Managed Streaming for Apache Kafka(Amazon MSK)について](http://iret.media/139304)

---

## 4. データベースの選定

### OLTP と OLAP の違い

いつもWebアプリで使ってるRDS (PostgreSQL, MySQL) はOLTP（トランザクション処理）用になります。しかし、データ分析ではOLAP（分析処理）用のDBを使います。「どっちもSQLですが？」と思うかもしれませんが、中身は全然違います。

#### OLTPシステムの特徴

OLTPシステムは、大量のトランザクションデータを処理するよう最適化されたリレーショナルデータベースにデータを保存します。

主な特徴：

- 正規化されたスキーマ: データの重複を排除し、整合性を保つ（第3正規形など）
- ACID トランザクション: Atomicity（原子性）、Consistency（一貫性）、Isolation（独立性）、Durability（永続性）を保証
- 高速な書き込み: INSERT、UPDATE、DELETE が頻繁に発生
- 単一レコード操作: 顧客の注文、商品の在庫更新など、1件ずつ処理

#### OLAPシステムの特徴

OLAPの多次元スキーマは、複数のデータセット（履歴データ、最新データ、外部データなど）からデータを取得する複雑なクエリに適しています。

主な特徴：

- 非正規化されたスキーマ: スタースキーマやスノーフレークスキーマで、JOINを最小化
- 読み取り中心: SELECT クエリが大半、更新は定期的なバッチ処理
- 集計に最適化: SUM、AVG、COUNT などの集計関数が高速
- 多次元分析: 時間軸、地域軸、商品軸など、複数の軸でデータを切り出し、分析できる

例: 集計クエリ

- 行指向: すべてのカラムを読み込む必要がある → 遅い
- 列指向: `City` と `Amount` のカラムだけ読み込む → 速い

#### 詳細比較

| 項目 | OLTP (トランザクション処理) | OLAP (分析処理) |
|------|--------------------------|----------------|
| 目的 | トランザクション処理 | 分析・集計処理 |
| データモデル | 正規化 | 非正規化、多次元スキーマ |
| ストレージ形式 | 行指向 | 列指向 |
| クエリパターン | 単純なSELECT、INSERT、UPDATE | 集計・分析クエリ（GROUP BY、SUM、COUNT） |
| 応答時間 | ミリ秒単位（即座にレスポンス） | 秒〜分単位（大量データ処理のため） |
| 更新頻度 | 秒単位でリアルタイム更新 | バッチ処理（日次、時間単位） |
| データ量 | GB〜数百GB | 数百GB〜ペタバイト |
| 同時実行 | 数千〜数万の同時トランザクション | 数十〜数百の同時クエリ |
| データソース | 単一アプリケーションからの最新データ | 複数システムからの履歴データ + 最新データ |
| 代表的なDB | RDS, Aurora | Redshift |
| 例 | ECサイトの注文処理、在庫管理 | 過去1年の売上分析、顧客行動分析 |

### レコード例

```
【行指向ストレージ (OLTP)】
Row 1: [ID=1, Name=Alice, Age=30, City=Tokyo, Amount=5000]
Row 2: [ID=2, Name=Bob,   Age=25, City=Osaka, Amount=3000]
Row 3: [ID=3, Name=Carol, Age=35, City=Tokyo, Amount=7000]
→ 1レコード全体を読み書きするのに最適

【列指向ストレージ (OLAP)】
ID:     [1, 2, 3]
Name:   [Alice, Bob, Carol]
Age:    [30, 25, 35]
City:   [Tokyo, Osaka, Tokyo]
Amount: [5000, 3000, 7000]
→ 特定のカラムだけを読み込む集計に最適
→ 同じ型のデータが連続するため圧縮効率が高い
```

---

### AWS データベース比較

#### RDS

特徴:

- AWSマネージドなOLTPデータベース
- 行指向ストレージ
- ACID トランザクション保証

用途:

- Webアプリケーション
- 業務システム
- トランザクション処理が中心

スケーラビリティ:

- 垂直スケール: インスタンスサイズ変更（例: t3.medium → r5.2xlarge）
- 水平スケール: リードレプリカ（読み取り専用コピー、最大15台）

コスト:

- インスタンス課金
- ストレージ課金
- リザーブドインスタンスで割引可能

---

#### Aurora

特徴:

- AWS独自開発の高性能OLTP DB
- PostgreSQLまたはMySQLと互換
- ストレージが自動スケール
- 高可用性

用途:

- 高性能が必要なトランザクション処理
- 高可用性が求められるシステム
- RDSからの移行

スケーラビリティ:

- 垂直スケール: 1プライマリインスタンス変更（例: t3.medium → r5.2xlarge）
- 水平スケール: リードレプリカ（読み取り専用コピー、最大15台、自動フェイルオーバー）
- Aurora Serverless: 自動スケール（最小〜最大ACUを設定）

コスト:

- RDSより高いが、パフォーマンスが良い
- I/O課金が発生する場合がある

---

#### S3 + Athena

特徴:

- サーバーレスクエリエンジン
- S3上のデータに対してSQLを実行
- 読み込み時にスキーマを適用するスキーマオンリード

用途:

- データレイク上でのアドホッククエリ
- 探索的分析
- 月次レポートなどの軽量な分析

スケーラビリティ:

- 自動スケール
- データ量に制限なし

コスト:

- スキャンしたデータ量で課金（$5 / TB）
- パーティショニングで必要なデータのみスキャン

Athena使うときの注意:

- パーティション切らないと全データスキャンされてコストが爆発してしまう
- `WHERE dt = '2026-02-01'` みたいにパーティションキーで絞り込む必要あり

---

#### Redshift

特徴:

- AWSマネージドなデータウェアハウス
- 列指向ストレージ
- MPP (Massively Parallel Processing) アーキテクチャ

用途:

- データウェアハウス
- 大量データの集計（例: 数百GB〜数TB）
- 定期的なBIレポート

スケーラビリティ:

- 水平スケール: ノードを追加（例: 2ノード → 4ノード → 8ノード）
- 垂直スケール: ノードタイプの変更（例: dc2 (SSD), ra3 (マネージドストレージ)）

コスト:

- ノード数 × ノードタイプ × 稼働時間
- リザーブドインスタンスで最大75%割引
- 使わない時間帯は停止しコストを抑える

Redshift使うときの注意:

- DISTKEY と SORTKEY の設定がパフォーマンスに直結します
- JOINで使うカラムをDISTKEYに、WHEREで絞り込むカラムをSORTKEYに設定する

---

### データベースの選定

データベースを選定する際は、データ量だけでなく、コスト、運用負荷、クラウド戦略、既存インフラとの統合性など、複数の観点から総合的に判断する必要があります。以下の比較表を参考にしてください。

#### データベース比較表

| 観点 | RDS | Aurora | S3 + Athena | Redshift |
|------|-----|--------|-------------|----------|
| カテゴリ | トランザクションDB | トランザクションDB | クエリエンジン | データウェアハウス |
| 用途 | OLTP（トランザクション処理） | OLTP（トランザクション処理） | OLAP（アドホック分析） | OLAP（データウェアハウス） |
| 適用データ量 | 〜数百GB | 〜数TB | 制限なし | 数百GB〜数十TB |
| クエリ頻度 | 高頻度（秒単位） | 高頻度（秒単位） | 低〜中頻度（月次・週次レポート） | 中〜高頻度（日次バッチ、BIツール） |
| コスト | 中（インスタンス課金） | 中〜高（インスタンス + I/O課金） | 低（スキャン量に応じた従量課金） | 高（ノード課金、リザーブドで割引可） |
| 運用負荷 | 中（パッチ適用、バックアップ自動化） | 低（自動フェイルオーバー、ストレージ自動スケール） | 最小（サーバーレス） | 中〜高（ノード管理、DISTKEY/SORTKEY設計） |
| パフォーマンス要件 | 低レイテンシ（ミリ秒単位） | 低レイテンシ（ミリ秒単位）、高可用性 | 中〜高レイテンシ（秒単位、パーティション設計に依存） | 中レイテンシ（秒単位）、大量データ集計に最適 |
| スケーラビリティ | 垂直スケール + リードレプリカ | 垂直 + 水平スケール、Aurora Serverless | 自動スケール | 水平スケール（ノード追加） |
| AWSエコシステム統合 | ネイティブ統合 | ネイティブ統合 | ネイティブ統合（S3、Glue、IAM） | ネイティブ統合（S3、Glue、Lambda、IAM） |
| 適用ユースケース | Webアプリケーション、業務システム | 高性能が必要なWebアプリ、高可用性システム | 探索的分析、月次レポート、ログ分析 | AWSで完結するDWH、日次レポート、BI分析 |

#### 選定フロー

データベースの選定は、以下の観点で判断します：

##### 1. トランザクション処理（OLTP）または分析処理（OLAP）

- トランザクション処理が中心 → OLTP
  - 高性能・高可用性が必要 → Aurora
  - それ以外 → RDS
- 分析処理が中心 → 2. OLAP へ

##### 2. OLAP の場合：クラウド戦略と既存インフラとの関係性

**AWSで完結させたい場合：**

- データ量が少ない（〜数十GB）+ 月次レポート程度 → S3 + Athena
- データ量が多い（数百GB〜数TB）+ 日次バッチ処理 → Redshift

Redshiftの特徴：

- S3、Glue、Lambda、Kinesis など AWS サービスとネイティブに統合
- IAM、VPC でセキュリティ統制しやすい
- 既にAWSを使っている場合、運用ノウハウを活かせる
- リザーブドインスタンスでコスト最適化しやすい

RDSからRedshiftへのデータロード:

- S3経由でロードするのが基本です（COPYコマンド使う）
- 直接JDBCで接続もできるけど、データ量が多いとS3経由の方が速いです

**SaaS型DWH（Snowflake / Databricks）が適している場合：**

- 運用負荷を極限まで下げたい（サーバー管理、チューニング作業が不要）
- コンピュートとストレージを分離し、複数チームで独立したリソースを使いたい
- 超大規模データ（数TB〜ペタバイト級）の処理
- 高度な機能（タイムトラベル、ゼロコピークローン、ML統合など）
- マルチクラウド戦略やベンダーロックイン回避を考慮

##### 3. その他の判断基準

- コスト優先なら
  - 初期コストを抑えたい → S3 + Athena（従量課金）
  - 安定したコスト → Redshift（リザーブドインスタンス活用）

- 運用負荷を最小化したいなら
  - サーバーレスが良い → S3 + Athena
  - マネージドで運用したい → Aurora、Redshift

- チームのスキルセット
  - AWSに精通している → Redshift
  - SQLで分析したい → Snowflake
  - Spark + 機械学習を活用したい → Databricks

---

### データレイク vs データウェアハウス vs データマート の詳細比較

データ基盤を設計する際、これら3つの概念を正しく理解し、使い分けることが重要です！

#### 詳細比較表

| 項目 | データレイク | データウェアハウス | データマート |
|------|------------|------------------|------------|
| データ形式 | 生データ、非構造化データも可 | 構造化データ、スキーマ定義済み | 要約されたリレーショナルデータ |
| スキーマ | 読み込み時に定義 | 書き込み時に定義 | 事前定義済み |
| 目的 | すべてのデータを保存（将来の活用に備える） | 組織全体の分析用に最適化 | 特定部門のニーズに特化 |
| スコープ | 全社横断 | 組織全体 | 営業、財務など単一部門 |
| ユーザー | データエンジニア、データサイエンティスト | ビジネスアナリスト | 特定チーム |
| 分析用途 | 機械学習、探索的分析 | BIレポート、ダッシュボード | 要約分析、部門レポート |
| 処理方式 | ELT | ETL | ウェアハウスからフィルタリング |
| データ品質 | 品質チェック不十分の可能性 | 高品質保証 | 高品質 |
| 代表例 | Amazon S3 | Redshift | 部門別Redshiftスキーマ |
| コスト | 低 | 中〜高 | 低〜中 |

#### データレイクの詳細

特徴:

- あらゆる形式のデータを保存できる：CSV, JSON, Parquet, Avro, ログファイル、画像、動画など
- スキーマを後で定義できる柔軟性がある
- 低コストで大量データを保存可能

メリット:

- 将来的なユースケースに備えてデータを保持
- 機械学習のトレーニングデータとして活用
- データの完全な履歴を保持

デメリット:

- データの沼になるリスクがある：管理されていないデータが蓄積
- データカタログが重要：何のデータがどこにあるか把握する仕組みが必要

AWS実装例:

- S3: オブジェクトストレージ
- AWS Glue Data Catalog: メタデータ管理
- Athena: アドホッククエリ

#### データウェアハウスの詳細

特徴:

- 構造化されたデータのみ
- 分析用に最適化されたスキーマ（例: スタースキーマ）
- 高速なクエリパフォーマンス

メリット:

- BIツールとの統合が容易
- データ品質が保証される
- SQLで分析可能

デメリット:

- スキーマ変更が困難
- コストが高い
- 非構造化データを扱えない

AWS実装例:

- Redshift: データウェアハウス

#### データマートの詳細

特徴:

- データウェアハウスのサブセット
- 特定の部門やプロジェクトに特化
- 小規模で管理しやすい

メリット:

- 部門固有のニーズに最適化
- データ量が少ないためクエリパフォーマンスが向上
- 権限管理が容易

デメリット:

- データが分散する可能性
- 部門間でデータの不整合が発生するリスク

AWS実装例:

- Redshiftのスキーマ分離

---

### 参考リンク

- [RDS vs Aurora どっち使う？](https://dev.classmethod.jp/articles/developers-io-2019-in-osaka-aurora-or-rds/)
- [データベース基礎：行ベース（行指向）と列ベース（列指向 / カラム型）の違いを整理する](https://qiita.com/yushibats/items/e02d60666dcd2c19f7dd)
- [Amazon Athenaの使い方まとめ](https://zenn.dev/amezousan/scraps/b9be79a1fbed8c)
- [OLAP vs OLTP の違い](https://aws.amazon.com/jp/compare/the-difference-between-olap-and-oltp/)
- [データウェアハウス vs データレイク vs データマート](https://aws.amazon.com/jp/compare/the-difference-between-a-data-warehouse-data-lake-and-data-mart/)

---

## 5. 学習してみて感じたこと

### DBの違い

今回データ基盤について学習してみて感じたのは、データの使い方が根本的に違うということです。そして、その違いを技術的に実現しているのが「行指向ストレージ」と「列指向ストレージ」の違いでした。

Webアプリケーションのインフラ（OLTP）:

- RDSを使って1レコード全体を更新・挿入することがメイン
- リアルタイム性が求められる（ミリ秒単位）
- 「行全体を高速に読み書きする」という設計思想
- 行指向ストレージ（RDS, Aurora）: 1レコード全体を読み書きするのに最適

データ基盤（OLAP）:

- 属性ごとに統計を取って分析することがメイン
- バッチ処理が中心
- 「列ごとにデータを集計する」という発想
- 列指向ストレージ（Redshift など）: 特定のカラムだけを集計するのに最適

これまでだと「1レコード全体の更新や挿入」がメインだったので、列ごとに最適化するという発想がありませんでした。しかし、データ分析では「全顧客の購入金額の合計」のように、特定の列だけを大量に読み込むクエリが中心になります。

```
# 例
Webアプリ: SELECT * FROM users WHERE id = 1;
  → 1人のユーザー情報を取得

データ分析: SELECT region, SUM(amount) FROM sales GROUP BY region;
  → 全レコードの region と amount だけを読み込んで集計
```

同じDBでも、使われ方が違うと大きく構成が変わるというのが最大の発見でした。この設計思想の違いが理解できたことで、データ基盤の全体像が腹落ちしました。

---

### 苦労したポイントと気づき

#### bronze/silver/goldの境界が曖昧だが、本質は「段階的な加工」

データレイクのレイヤー分け（bronze/silver/gold）について学習しましたが、最初は「どこまでがbronze、どこからがsilver」という明確な基準がないことに戸惑いました。

- bronze: ここは比較的明確
- silver: "軽微な変換"とはどこまでを指すのか？型変換だけ？NULL埋めも含む？
- gold: "ビジネスロジックを適用"とあるけど具体的には？

しかし、勉強していく中で気づいたのは、大事なのは「3層に分ける」ことではなく、「段階的にデータを加工する」という考え方だということです。

実際、プロジェクトによっては：

- シンプルに `raw` / `processed` の2層構成
- 細かく `raw` / `cleaned` / `enriched` / `mart` の4層構成

など、レイヤー数も定義も変わります。重要なのは以下の点：

1. 生データを保持する（監査・検証のため変更不可で保存）
2. 段階的に加工する（エラー時のデバッグや再利用がしやすい）
3. 最終的に分析用データを作る（BIツールやMLモデルで使える形）

明確な正解はなく、プロジェクトの要件に合わせて設計するものだと理解しました。このイメージを持っていれば、自分のプロジェクトでも構築していけると思います。

#### ETLが複数箇所で必要という意外性

ETL処理について調べていく中で、ETLがデータパイプラインの複数箇所で必要になることに驚きました。

1. データソース → データレイク（bronze）: 各種データソースからS3にデータを投入する際のETL
2. bronze → silver → gold: データレイク内での段階的な変換のためのETL

特に大規模プロジェクトでは、一度S3を介してデータを保存し、さらに別のDBにロードするという"DB2個でやっていくイメージ"が意外でした。Webアプリでは RDS1つで完結することが多いため、この多段階構成は新鮮でした。

---

### これから取り組む際に気をつけたいこと

#### 1. まずは概念の理解から始めたい

データ基盤を学習する中で、最初に躓きやすいと感じたのが「概念の理解」でした。

- OLTP vs OLAP: トランザクション処理と分析処理の違い
- データレイク vs データウェアハウス: 生データと構造化データの違い

これまでやってこなかったリソースが多いので、改めて勉強が必要だと感じました。Webアプリのインフラ経験があっても、データ基盤は別領域として学び直す必要がありそうです。

しかし、これらの基本概念を理解しておくと、各ツール（Athena、Redshift など）をどう使っていけば良いのか理解しやすくなりました。

#### 2. コスト監視は最初から設定したい

データ基盤は、Webアプリのインフラとはコスト構造が異なります。

- Webアプリ: インスタンスの稼働時間で課金
- データ基盤: データのスキャン量、DPU時間、ノード数で課金

特にAthenaは、パーティションを切らずに全データスキャンすると想定外のコストが発生します。ケアレスミスでコストが爆増しないためにも最初からAWS Cost Explorerでアラートを設定しておくのが大事だと感じました。

#### 3. 実際に手を動かして試したい

データ基盤は、やってみないと理解が難しいと感じました。

- ドキュメントを読むだけでは分からないことが多い
- 実際にAthenaでクエリを投げてみる、Glue ETLジョブを動かしてみる、という経験が重要
- PoC（概念実証）や小規模な検証環境で試してから本番構成を決めるのが良さそう

簡単に実践した方が理解が深まります。AWSの無料枠を使って試すのも良いと思います。
自分もやってみます！

#### 4. 選択肢の多さに惑わされないようにしたい

データ基盤には多くのツールがあり、最初は「どれを選べばいいのか」迷います。

- AWSのツールのみで完結もできる（例: Lambda + S3 + Athena + Redshift + Glue）
- 構成の多くをカバーしてくれるSnowflake/Databricksなどの専用ツールもある

一度概念を理解していれば、どのツールを使っても基本は同じです。自分のプロジェクトの要件（データ量、リアルタイム性、予算、社内のスキルセット）に合わせて選ぶのがポイントですね。

#### 5. ネット上の情報を積極的に活用したい

データエンジニアリングは近年注目されている分野なので、大量の記事があります。

- AWS公式ドキュメント
- Snowflake/Databricksの公式チュートリアル
- Qiita、Zenn、個人ブログ

同じような悩みを持った人の記事を探すと、解決策が見つかることが多いです。実際に今回の学習でも、多くの先人の記事に助けられました。

---

## 6. まとめ

この記事では、インフラエンジニアがデータ基盤を構築する際の基礎知識を学びました。

### 本記事で学んだこと

1. データ基盤の全体像: OLTP と OLAP、データレイク と データウェアハウス
2. インフラ構成パターン: 小規模（Lambda + S3 + Athena）、AWS完結型（Glue + Redshift + dbt）、SaaS型（Kinesis + Databricks/Snowflake）
3. データベース選定: RDS、Aurora、Athena、Redshift の特徴と使い分け
4. 行指向vs列指向ストレージ: データ量とクエリパターンに応じた選択基準

---

### 次回:【設計・ツール選定編】

次回は、データモデリングの詳細とツール選定を解説します：

- データモデリング詳説: スタースキーマ、ファクトテーブル、ディメンションテーブル
- ETL/ELT実装: AWS Glue、Lambda、Step Functions、dbt
- Snowflake と Databricks: アーキテクチャ比較と選定基準

---
