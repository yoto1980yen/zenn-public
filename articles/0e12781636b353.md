---
title: "Webアプリのインフラエンジニアがデータ基盤を構築するので勉強してみた"
emoji: "🗄️"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["AWS", "DataEngineering", "Redshift", "Athena", "dbt"]
published: false
publication_name: finatext
---

## Webアプリを作ってきたインフラエンジニアがデータ基盤に挑戦するときの道しるべ

これは何？
インフラエンジニアがAIと一緒に学びながらまとめた、データ基盤構築のナレッジです。
「EC2やRDS、ALBなど触れてきましたが、データ基盤には触れていなかったので、データエンジニアリングってどうやるの？」という疑問から始まった学習記録を、共有できる形にしました。

想定読者:

- Webアプリのインフラは分かるけど、データ基盤は初めて
- RDSとRedshiftって何が違うの？OLTP vs OLAPって何？
- データレイクとデータウェアハウスってどう使い分けるの？

前提知識:

- AWS基礎（EC2, ALB, RDS, S3くらい触ったことある）
- SQL基礎（SELECT文書ける）

---

## 目次

1. [概要](#1-概要)
2. [前提知識](#2-前提知識)
3. [実際に作るとなるとどんなインフラ構成になるか](#3-実際に作るとなるとどんなインフラ構成になるか)
   - [パターンA: 小規模構成](#パターンa-小規模構成-数gb月次レポート程度)
   - [パターンB: 中規模構成](#パターンb-中規模構成-数十gb数tb日次分析)
   - [パターンC: 大規模構成](#パターンc-大規模構成-数tb以上リアルタイム分析)
4. [データベースの選定](#4-データベースの選定)
5. [学習してみて感じたこと](#5-学習してみて感じたこと)
6. [まとめ](#6-まとめ)

---

## 1. 概要

### データ基盤とは何か

**データ基盤（Data Platform）** とは、企業が持つ様々なデータを**収集・保存・変換・分析・活用**するための統合的なインフラストラクチャです。インフラエンジニアがこれまで扱ってきたWebアプリケーションのインフラ（EC2, ALB, RDS）とは異なり、データ基盤は**「大量のデータを効率的に処理し、ビジネス価値を生み出すための分析環境」**を提供します。

### なぜデータ基盤が必要なのか

従来のWebアプリケーション用のデータベース（RDS, Aurora）は、**トランザクション処理に最適化**されています。しかし、以下のような**分析ニーズには適していない**です：

- 数年分の売上データを集計して傾向を分析したい
- 複数のシステムからデータを統合して全社的なレポートを作成したい
- 機械学習モデルを使って予測分析を行いたい

こうしたニーズに応えるために、**分析専用のデータ基盤**が必要になります。

### OLTP vs OLAP

#### 共通点

**OLTP（トランザクション処理）** と**OLAP（分析処理）** は、どちらも以下の基本機能を提供します：

- データの保存: 構造化されたデータをデータベースに永続化
- SQLクエリ: SQL言語を使ったデータの検索・取得
- リレーショナルDB: 多くの場合、リレーショナルデータベース管理システム（RDBMS）を使用
- セキュリティ: アクセス制御、暗号化、監査ログ

しかし、**設計思想と最適化の方向性が根本的に異なります**。

#### 違いの詳細比較

| 項目 | OLTP (Online Transaction Processing) | OLAP (Online Analytical Processing) |
|------|-------------------------------------|-------------------------------------|
| 目的 | トランザクション処理（CRUD操作） | 分析・集計処理 |
| データモデル | 正規化（重複を排除） | 非正規化（JOINを減らす）、多次元スキーマ |
| ストレージ形式 | 行指向（Row-oriented） | 列指向（Column-oriented） |
| クエリパターン | 単純なSELECT、INSERT、UPDATE | 集計・分析クエリ（GROUP BY、SUM、COUNT） |
| 応答時間 | ミリ秒単位（即座にレスポンス） | 秒〜分単位（大量データ処理のため） |
| 更新頻度 | 秒単位でリアルタイム更新 | バッチ処理（日次、時間単位） |
| データ量 | GB〜数百GB | 数百GB〜ペタバイト |
| 同時実行 | 数千〜数万の同時トランザクション | 数十〜数百の同時クエリ |
| データソース | 単一アプリケーションからの最新データ | 複数システムからの履歴データ + 最新データ |
| 代表的なDB | RDS (PostgreSQL, MySQL), Aurora | Redshift, Snowflake, BigQuery |
| 例 | ECサイトの注文処理、在庫管理 | 過去1年の売上分析、顧客行動分析 |

#### OLTPシステムの特徴

OLTPシステムは、**大量のトランザクションデータを処理するよう最適化**されたリレーショナルデータベースにデータを保存します。主な特徴：

- **正規化されたスキーマ**: データの重複を排除し、整合性を保つ（第3正規形など）
- **ACID トランザクション**: Atomicity（原子性）、Consistency（一貫性）、Isolation（独立性）、Durability（永続性）を保証
- **高速な書き込み**: INSERT、UPDATE、DELETE が頻繁に発生
- **単一レコード操作**: 顧客の注文、商品の在庫更新など、1件ずつ処理

#### OLAPシステムの特徴

OLAPの多次元スキーマは、**複数のデータセット（履歴データ、最新データ、外部データなど）からデータを取得する複雑なクエリ**に適しています。主な特徴：

- **非正規化されたスキーマ**: スタースキーマやスノーフレークスキーマで、JOINを最小化
- **読み取り中心**: SELECT クエリが大半、更新は定期的なバッチ処理
- **集計に最適化**: SUM、AVG、COUNT などの集計関数が高速
- **多次元分析**: 時間軸、地域軸、商品軸など、複数の軸でデータをスライス&ダイス

### データパイプラインの基本フロー

```
[データソース]
    ↓
[収集 (Extract)]
    ↓
[保存 (Load - データレイク)]
    ↓
[変換 (Transform)]
    ↓
[保存 (データウェアハウス)]
    ↓
[分析・可視化]
```

### 本記事で学べること

- データ基盤の全体像: OLTP vs OLAP、データレイク vs データウェアハウス
- インフラ構成パターン: 小規模（Lambda + S3 + Athena）、中規模（Glue + Redshift + dbt）、大規模（Kinesis + Databricks/Snowflake）
- データベース選定: RDS、Aurora、Athena、Redshift の特徴と使い分け
- 行指向vs列指向ストレージ: データ量とクエリパターンに応じた選択基準

---

## 2. 前提知識

この記事は、EC2やRDSなどWebアプリケーションのインフラは触ってきたけど、データ基盤は初めて、というインフラエンジニアを対象としています。以下のような知識があれば読み進められます：

### AWS基本サービス

- EC2 (Elastic Compute Cloud): 仮想サーバーの起動・管理
- S3 (Simple Storage Service): オブジェクトストレージの基本操作
- VPC (Virtual Private Cloud): ネットワーク構成の基礎
- IAM (Identity and Access Management): ロールとポリシーによる権限管理

### SQL基礎

- 基本クエリ: `SELECT`, `WHERE`, `ORDER BY`, `GROUP BY`
- テーブル結合: `JOIN` (INNER, LEFT, RIGHT)
- 集計関数: `COUNT`, `SUM`, `AVG`, `MAX`, `MIN`

---

## 3. 実際に作るとなるとどんなインフラ構成になるか

「データ基盤を構築してください」って言われても、**データ量やコストによって全然違う構成**になります。ここでは、AWSを使った代表的な**3パターン（小・中・大規模）**を調べました。自分のプロジェクトがどのパターンに当てはまるか考えながら読んでみてください。

---

### パターンA: 小規模構成 (〜数GB、月次レポート程度)

#### 対象

- 学習目的、PoC（概念実証）
- スタートアップや小規模プロジェクト
- 初期コストを抑えたい場合

#### 構成図

```
[データソース]
   (RDS, CSV, API)
        |
        v
  [AWS Lambda]
   (データ収集・軽量な変換)
        |
        v
   [Amazon S3]
   (データレイク)
   ├── raw/        (生データ - Bronze層)
   └── processed/  (変換後データ - Silver層)
        |
        v
  [AWS Glue Data Catalog]
   (テーブル定義・メタデータ管理)
        |
        v
  [Amazon Athena]
   (SQLでアドホッククエリ)
        |
        v
[QuickSight / Metabase]
   (BIツールで可視化)
```

#### 特徴

1. **サーバーレス中心**
   - サーバー管理不要、運用負荷が低い
   - Lambda: データ収集、軽量な変換処理
   - Glue Data Catalog: テーブル定義の管理(メタデータストア)
   - Athena: S3上のデータに対してSQLクエリを実行

2. **従量課金**
   - 初期コスト不要、使った分だけ課金
   - スモールスタートに最適

3. **制約**
   - 複雑な変換処理には不向き（Lambda: メモリ10GB、実行時間15分まで）
   - Athena: クエリのたびにS3をスキャン（大量データでコスト増）

#### コスト考慮ポイント（お金かかるとこ）

| サービス | 何に課金されるか | どうやってコスト抑えるか |
|---------|---------|---------------------|
| S3 | 保存してるデータ量 | 古いデータはGlacierに自動移行。ライフサイクルポリシー設定しとくと楽 |
| Glue Data Catalog | メタデータオブジェクト数 | 100万オブジェクトまで無料。普通は課金されない |
| Athena | SQLでスキャンしたデータ量 | パーティション切らないとめっちゃスキャンされて課金爆発する。絶対やる |
| Lambda | 実行時間とメモリ | メモリは必要最小限に。バッチ処理でまとめて実行するとコスト減る |
| QuickSight | ユーザー数 | Readerライセンス（閲覧のみ）使うと安い |

ポイント:

- Lambda + S3 + Glue Data Catalog + Athena で**サーバーレスなパイプライン**が作れます
- Glue Data Catalogはテーブル定義を管理(100万オブジェクトまで無料)
- **パーティション設計が大事**です（dt=YYYY-MM-DD みたいに日付で切る）
- Terraformでインフラをコード管理するのが定石です

#### 参考リンク

- [Athenaの使い方と料金の仕組み（AWS公式・日本語）](https://aws.amazon.com/jp/athena/) - 公式ページ
- [Athenaのパーティション活用（AWS公式ドキュメント・日本語）](https://docs.aws.amazon.com/ja_jp/athena/latest/ug/partitions.html) - パーティション切らないとスキャン量爆発する
- [Athena関連記事（Qiita）](https://qiita.com/tags/athena) - Tipsがたくさん
- [S3上のデータをAWS Athena/Glue で読み取る（Qiita）](https://qiita.com/siwa/items/86a5323094795eb55d2a) - 構造化の例

---

### パターンB: 中規模構成 (数十GB〜数TB、日次分析)

#### 対象

- 実務レベルのデータ分析基盤
- 安定したパフォーマンスが必要
- 日次バッチ処理、定期的なレポート作成

#### 構成図

```
[データソース]
  (RDS, API, ログ)
        |
        v
   [AWS Glue] ← ①抽出: RDS→S3
  (ETLジョブ - Spark)
        |
        v
   [Amazon S3]
   (データレイク)
   ├── raw/        (生データ - Bronze層)
   |       ↓
   |   [AWS Glue] ← ②軽微な変換: CSV→Parquet、型変換
   |       ↓
   ├── staging/    (中間データ - Silver層)
   |       ↓
   |   [AWS Glue] ← ③ロード: S3→Redshift (COPY)
   |       ↓
   └── warehouse/  (分析用データ - Gold層)
        |
        v
  [Amazon Redshift]
  (データウェアハウス)
        |
        v
     [dbt] ← ④DWH内での変換: SQL (JOIN、集計、ビジネスロジック)
        |
        v
  [Redshift: Martテーブル]
        |
        v
[Tableau / Looker / QuickSight]
  (BIツール)
```

注: **Glue は「データレイクへの投入と整形」、dbt は「DWH内での変換」を担当**

#### 特徴

1. **Redshift: データウェアハウス**
   - **列指向ストレージ**: 集計クエリが高速
   - **MPP (Massively Parallel Processing)**: 並列処理で大量データを処理
   - 数百GB〜数TBのデータに最適

2. **AWS Glue: マネージドETL**
   - Sparkベース: 複雑なデータ変換が可能
   - Data Catalog: メタデータ管理（テーブル定義、スキーマ）
   - サーバーレス: インフラ管理不要

3. **dbt (data build tool): SQLベースの変換**
   - モダンデータスタックの標準ツール
   - バージョン管理、テスト、ドキュメント生成が可能
   - SQLが書ければ使える（学習コスト低）

4. **データレイヤー分け**
   - **Raw層（Bronze）**: 生データ（変更不可、監査証跡）
   - **Staging層（Silver）**: 軽微な変換後のデータ
   - **Warehouse/Mart層（Gold）**: ビジネスロジックを適用した分析用データ

#### コスト考慮ポイント（ここは結構お金かかる）

| サービス | 何に課金されるか | どうやってコスト抑えるか |
|---------|---------|---------------------|
| Redshift | ノード数 × サイズ × 稼働時間 | リザーブドインスタンス買うと最大75%オフ。使わない時間は一時停止しとくとコスト減る |
| AWS Glue | DPU時間（Sparkの実行時間） | 増分処理にして全データ処理しない。ワーカー数も必要最小限に |
| S3 | データ量 | 初期数日間だけ参照され、その後は保管だけされるデータはS3 Glacierに移行するなどライフサイクルポリシー設定を行う |

ポイント:

- Glue ETLでPySparkを書きます（SparkはDatabricksに比べると学習コスト高めです）
- **Redshift の DISTKEY と SORTKEY がパフォーマンスに直結**します
- dbt は SQLでデータ変換を書けるから、アナリストも参加しやすい
- **Raw → Staging → Mart という段階的なデータ変換**が定石

#### 参考リンク（実際に使ってみて参考になったやつ）

- [dbt入門（Qiita）](https://qiita.com/shun198/items/4e26f776c67c06e55a95) - SQLでデータ変換、実践的で分かりやすい
- [モダンデータスタックとは（Zenn）](https://zenn.dev/rwcolinpeng/articles/9b8040aa689556) - dbt、Fivetran、Snowflakeとかの全体像が理解できる
- [Redshiftベストプラクティス（AWS公式・日本語）](https://docs.aws.amazon.com/ja_jp/redshift/latest/dg/best-practices.html) - DISTKEY、SORTKEYの設計指針
- [Redshift関連記事（Developers.IO）](https://dev.classmethod.jp/tags/amazon-redshift/) - 実践的なTipsがたくさん

---

### パターンC: 大規模構成 (数TB以上、リアルタイム分析)

#### 対象

- エンタープライズレベル
- リアルタイム処理が必要
- 機械学習モデルの活用

#### 構成図

```
[データソース]
  (Kafka, Kinesis, RDS CDC)
        |
        v
[Amazon Kinesis / MSK]
  (ストリーミングデータ収集)
        |
        v
[AWS Glue / Spark on EMR]
  (リアルタイムETL)
        |
        v
   [Amazon S3]
  (Delta Lake / Apache Iceberg)
   ├── bronze/  (生データ - Raw層)
   ├── silver/  (クレンジング済み - Staging層)
   └── gold/    (集約済み - Warehouse層)
        |
        v
[Snowflake / Databricks]
  (統合分析プラットフォーム)
        |
        +--------+--------+
        |                 |
        v                 v
  [BIツール]      [SageMaker / MLflow]
                   (機械学習)
```

#### 特徴

1. **ストリーミング処理**
   - Kinesis Data Streams: AWSマネージド、シンプルな構成
   - Amazon MSK (Managed Streaming for Kafka): Kafkaのマネージドサービス
   - **リアルタイムでデータを収集・処理**

2. **トランザクショナルなデータレイク**
   - **Delta Lake**: Databricks開発、ACID トランザクション対応
   - **Apache Iceberg**: Netflixが開発、テーブルフォーマットの標準化
   - **データレイクでUPDATE, DELETE, MERGEが可能に**

3. **Snowflake / Databricks**
   - スケーラビリティが高い（ペタバイト級のデータに対応）
   - マルチクラウド対応（AWS, Azure, GCPで動作）
   - **コンピュートとストレージが分離**（独立してスケール）

4. **機械学習統合**
   - SageMaker: AWSのマネージドML環境
   - Databricks ML: Sparkと統合されたML環境、MLflow対応

#### コスト考慮ポイント（ここは本格的にお金かかる）

| サービス | 何に課金されるか | どうやってコスト抑えるか |
|---------|---------|---------------------|
| Kinesis Data Streams | シャード数 × 時間 | オンデマンドモード使うと自動でスケールしてくれる。シャード数は必要最小限に |
| Amazon MSK | Kafkaブローカー数 × サイズ | ストレージ自動スケールONにしとく |
| Snowflake | ウェアハウス稼働時間 + データ量 | 自動停止絶対設定する。アイドル時間設定しないとずっと課金される |
| Databricks | DBU × 稼働時間 + EC2コスト | 自動終了設定必須。スポットインスタンス使うと最大90%オフ |
| EMR | EC2インスタンス × 時間 | スポットインスタンス使う。ジョブ終わったらクラスター消す |

ポイント:

- **Kinesis でリアルタイムにデータを流す**（Kafkaみたいなやつ）
- **Delta Lake を使うとS3でもUPDATE/DELETE/MERGEができる**
- Snowflake: SQLファーストのデータウェアハウス、BIツール連携が強い（詳細はPart2で解説）
- Databricks: Spark + ML統合、Notebookで試行錯誤しやすい（詳細はPart2で解説）
- **ストリーミング処理はチェックポイント管理が大事**

#### 参考リンク（リアルタイム処理を学ぶときに読んだやつ）

- [【AWS入門】リアルタイムデータ処理の要！Amazon Kinesis Data Streamsを徹底解説](https://nakaterux.hatenablog.com/entry/2025/06/13/205143/) - ストリーミング処理の基本が分かる
- [Delta Lakeとは何か（Qiita）](https://qiita.com/taka_yayoi/items/07c9396809edbf2699b6) - データレイクでトランザクション使える
- [Databricks のチュートリアルを始める](https://docs.databricks.com/gcp/ja/getting-started/) - ノートブックで試しながら学べる
- [Snowflakeで始めるData Lake - Apache Icebergの基本と活用法 -](https://zenn.dev/kokisato/articles/419f4328b13dd5) - Snowflakeで使う場合について
- [入門者向けAmazon Managed Streaming for Apache Kafka(Amazon MSK)について](http://iret.media/139304) - Amazon MSK、Apache Kafkaについて概要がわかる

---

## 4. データベースの選定

### OLTP vs OLAP の違い

いつもWebアプリで使ってるRDS (PostgreSQL, MySQL) は**OLTP（トランザクション処理）用**になります。しかし、データ分析では**OLAP（分析処理）用のDB**を使います。「どっちもSQLじゃん？」って思うかもですが、**中身は全然違います**。

#### 詳細比較

| 項目 | OLTP (トランザクション処理) | OLAP (分析処理) |
|------|--------------------------|----------------|
| 処理パターン | 個別レコードの読み書き（CRUD） | 大量レコードの集計・分析 |
| クエリ特性 | 単純なSELECT, INSERT, UPDATE | 複雑なJOIN, GROUP BY, 集計関数 |
| データモデル | 正規化（3NF） | 非正規化（スタースキーマ） |
| ストレージ形式 | 行指向（Row-oriented） | 列指向（Column-oriented） |
| インデックス | B-Treeインデックス（特定レコード検索） | 列ごとの圧縮、ソートキー |
| 同時実行 | 数千〜数万の同時トランザクション | 数十〜数百の同時クエリ |
| 応答時間 | ミリ秒単位 | 秒〜分単位 |
| データ量 | GB〜数百GB | 数百GB〜ペタバイト |
| 更新頻度 | 秒単位でリアルタイム更新 | バッチ処理（日次、時間単位） |
| 目的 | 業務アプリケーション | BIレポート、ダッシュボード |

#### 行指向 vs 列指向のストレージ

```
【行指向ストレージ (OLTP)】
Row 1: [ID=1, Name=Alice, Age=30, City=Tokyo, Amount=5000]
Row 2: [ID=2, Name=Bob,   Age=25, City=Osaka, Amount=3000]
Row 3: [ID=3, Name=Carol, Age=35, City=Tokyo, Amount=7000]
→ 1レコード全体を読み書きするのに最適

【列指向ストレージ (OLAP)】
ID:     [1, 2, 3]
Name:   [Alice, Bob, Carol]
Age:    [30, 25, 35]
City:   [Tokyo, Osaka, Tokyo]
Amount: [5000, 3000, 7000]
→ 特定のカラムだけを読み込む集計に最適
→ 圧縮効率が高い（同じ型のデータが連続）
```

**例: 集計クエリ**

- **行指向**: すべてのカラムを読み込む必要がある → 遅い
- **列指向**: `City` と `Amount` のカラムだけ読み込む → 速い

---

### AWS データベース比較

#### RDS (PostgreSQL / MySQL)

特徴:

- AWSマネージドなOLTPデータベース
- 行指向ストレージ
- ACID トランザクション保証

用途:

- Webアプリケーション
- 業務システム
- トランザクション処理が中心

スケーラビリティ:

- 垂直スケール: インスタンスサイズ変更（t3.medium → r5.2xlarge）
- 水平スケール: リードレプリカ（読み取り専用コピー、最大15台）

コスト:

- インスタンス課金（時間単位）
- ストレージ課金（GB単位）
- リザーブドインスタンスで割引

---

#### Aurora

特徴:

- AWS独自開発の高性能OLTP DB
- PostgreSQLまたはMySQLと互換
- ストレージが自動スケール（最大128TB）
- 高可用性（3AZに6コピー自動レプリケーション）

用途:

- 高性能が必要なトランザクション処理
- 高可用性が求められるシステム
- RDSからの移行

スケーラビリティ:

- 書き込み: 1プライマリインスタンス（垂直スケール）
- 読み取り: リードレプリカ（最大15台、自動フェイルオーバー）
- Aurora Serverless: 自動スケール（最小〜最大ACUを設定）

コスト:

- RDSより高いが、パフォーマンスが良い
- I/O課金が発生する場合がある

---

#### S3 + Athena

特徴:

- **サーバーレスクエリエンジン**
- S3上のデータに対してSQLを実行
- **スキーマオンリード**（読み込み時にスキーマを適用）

用途:

- データレイク上でのアドホッククエリ
- 探索的分析（データを試しに見てみる）
- 軽量な分析（月次レポート程度）

スケーラビリティ:

- 自動スケール（クエリごとにリソースを自動割り当て）
- データ量に制限なし（ペタバイト級も可能）

コスト:

- スキャンしたデータ量で課金（$5 / TB）
- パーティショニングで必要なデータのみスキャン

Athena使うときの注意:

- **パーティション切らないと全データスキャンされてコストが爆発**してしまう
- `WHERE dt = '2026-02-01'` みたいに**パーティションキーで絞り込む**必要あり

---

#### Redshift

特徴:

- **AWSマネージドなデータウェアハウス**
- **列指向ストレージ**
- **MPP (Massively Parallel Processing) アーキテクチャ**

用途:

- データウェアハウス
- 大量データの集計（数百GB〜数TB）
- 定期的なBIレポート

スケーラビリティ:

- 水平スケール: ノードを追加（2ノード → 4ノード → 8ノード）
- ノードタイプ: dc2 (SSD), ra3 (マネージドストレージ)

コスト:

- ノード課金（ノード数 × ノードタイプ × 稼働時間）
- リザーブドインスタンスで最大75%割引
- 一時停止機能（使わない時間帯は停止）

Redshift使うときの注意:

- **DISTKEY と SORTKEY の設定がパフォーマンスに直結**します
- **JOINで使うカラムをDISTKEYに、WHEREで絞り込むカラムをSORTKEYに設定**する

---

### 選定フローチャート

```
データベースを選ぶ時のフローチャート:

トランザクション処理が中心？
  ├─ Yes → OLTP
  │   ├─ 高性能・高可用性が必要？
  │   │   ├─ Yes → Aurora
  │   │   └─ No  → RDS
  │
  └─ No → OLAP
      ├─ データ量は？
      │   ├─ 〜数十GB → S3 + Athena
      │   ├─ 数百GB〜数TB → Redshift
      │   └─ 数TB以上 → Snowflake / Databricks (Part2で解説)
      │
      └─ クエリ頻度は?
          ├─ 月次レポート程度 → S3 + Athena
          ├─ 日次バッチ処理 → Redshift
          └─ リアルタイム分析 → Snowflake / Databricks (Part2で解説)
```

RDSからRedshiftへのデータロード:

- S3経由でロードするのが基本です（COPYコマンド使う）
- 直接JDBCで接続もできるけど、データ量が多いとS3経由の方が速いです

---

### データレイク vs データウェアハウス vs データマート の詳細比較

データ基盤を設計する際、**これら3つの概念を正しく理解し、使い分けることが重要**！

#### 詳細比較表

| 項目 | データレイク | データウェアハウス | データマート |
|------|------------|------------------|------------|
| データ形式 | 生データ（Raw）、非構造化データも可 | 構造化データ、スキーマ定義済み | 要約されたリレーショナルデータ |
| スキーマ | 読み込み時に定義（Schema-on-Read） | 書き込み時に定義（Schema-on-Write） | 事前定義済み |
| 目的 | すべてのデータを保存（将来の活用に備える） | 組織全体の分析用に最適化 | 特定部門のニーズに特化 |
| スコープ | 全社横断 | 組織全体 | 単一部門（営業、財務など） |
| ユーザー | データエンジニア、データサイエンティスト | ビジネスアナリスト | 特定チーム |
| 分析用途 | 機械学習、探索的分析 | BIレポート、ダッシュボード | 要約分析、部門レポート |
| 処理方式 | ELT（後で変換） | ETL（事前変換） | ウェアハウスからフィルタリング |
| データ品質 | 品質チェック不十分の可能性 | 高品質保証（事前クリーニング） | 高品質（ウェアハウスから派生） |
| 代表例 | Amazon S3, Azure Data Lake Storage | Redshift, Snowflake, BigQuery | 部門別Redshiftスキーマ |
| コスト | 低（ストレージが安い） | 中〜高（コンピュートコストが高い） | 低〜中（ウェアハウスの一部） |

#### データレイクの詳細

特徴:

- **あらゆる形式のデータを保存できる**：CSV, JSON, Parquet, Avro, ログファイル、画像、動画など
- **スキーマを後で定義できる柔軟性**がある
- 低コストで大量データを保存可能

メリット:

- 将来的なユースケースに備えてデータを保持
- 機械学習のトレーニングデータとして活用
- データの完全な履歴を保持

デメリット:

- **データの沼（Data Swamp）になるリスク**がある：管理されていないデータが蓄積
- **データカタログが重要**：何のデータがどこにあるか把握する仕組みが必要

AWS実装例:

- S3: オブジェクトストレージ
- AWS Glue Data Catalog: メタデータ管理
- Athena: アドホッククエリ

#### データウェアハウスの詳細

特徴:

- **構造化されたデータのみ**
- **分析用に最適化されたスキーマ**（スタースキーマなど）
- **高速なクエリパフォーマンス**

メリット:

- BIツールとの統合が容易
- **データ品質が保証される**
- SQLで分析可能

デメリット:

- **スキーマ変更が困難**
- コストが高い（コンピュートリソース）
- 非構造化データを扱えない

AWS実装例:

- Redshift: データウェアハウス
- Snowflake: クラウドDWH（AWS上で動作）

#### データマートの詳細

特徴:

- **データウェアハウスのサブセット**
- **特定の部門やプロジェクトに特化**
- 小規模で管理しやすい

メリット:

- 部門固有のニーズに最適化
- クエリパフォーマンスが向上（データ量が少ない）
- 権限管理が容易

デメリット:

- データが分散する可能性
- 部門間でデータの不整合が発生するリスク

AWS実装例:

- Redshiftのスキーマ分離
- 部門別のSnowflakeウェアハウス

#### データレイク + データウェアハウス のハイブリッド構成

**モダンなデータ基盤では、両方を組み合わせて使います**：

```
[データソース]
     ↓
[データレイク (S3)]
   - 生データを低コストで保存
   - 履歴データの完全な保持
     ↓
[ETL/ELT処理]
     ↓
[データウェアハウス (Redshift/Snowflake)]
   - 分析用に最適化されたデータ
   - BIツールでクエリ
     ↓
[データマート]
   - 部門別の集約データ
```

---

### 参考リンク（DB選定で参考にしたやつ）

- [RDS vs Aurora どっち使う？（Developers.IO）](https://dev.classmethod.jp/articles/developers-io-2019-in-osaka-aurora-or-rds/) - コストとパフォーマンスのトレードオフが分かる
- [データベース基礎：行ベース（行指向）と列ベース（列指向 / カラム型）の違いを整理する（Qiita）](https://qiita.com/yushibats/items/e02d60666dcd2c19f7dd) - 行指向との違いが理解できる
- [Amazon Athenaの使い方まとめ](https://zenn.dev/amezousan/scraps/b9be79a1fbed8c) - パーティション大事
- [OLAP vs OLTP の違い（AWS公式・日本語）](https://aws.amazon.com/jp/compare/the-difference-between-olap-and-oltp/) - 図解付きで分かりやすい
- [データウェアハウス vs データレイク vs データマート（AWS公式）](https://aws.amazon.com/jp/compare/the-difference-between-a-data-warehouse-data-lake-and-data-mart/) - 使い分けが理解できる

---

## 5. 学習してみて感じたこと

### Webアプリのインフラとの最大の違い：行指向 vs 列指向

今回データ基盤について学習してみて感じたのは、**データの使い方が根本的に違う**ということです。そして、その違いを技術的に実現しているのが「行指向ストレージ」と「列指向ストレージ」の違いでした。

**Webアプリケーションのインフラ（OLTP）:**

- RDSを使って**1レコード全体を更新・挿入**することがメイン
- リアルタイム性が求められる（ミリ秒単位）
- 「行全体を高速に読み書きする」という設計思想
- **行指向ストレージ（RDS, Aurora）**: 1レコード全体を読み書きするのに最適

**データ基盤（OLAP）:**

- **属性ごとに統計を取って分析する**ことがメイン
- バッチ処理が中心（秒〜分単位）
- 「列ごとにデータを集計する」という発想
- **列指向ストレージ（Redshift, Snowflake）**: 特定のカラムだけを集計するのに最適

これまでだと「1レコード全体の更新や挿入」がメインだったので、**列ごとに最適化する**という発想がありませんでした。しかし、データ分析では「全顧客の購入金額の合計」のように、特定の列だけを大量に読み込むクエリが中心になります。

```
# 例
Webアプリ: SELECT * FROM users WHERE id = 1;
  → 1人のユーザー情報（全カラム）を取得

データ分析: SELECT region, SUM(amount) FROM sales GROUP BY region;
  → 全レコードの region と amount だけを読み込んで集計
```

**同じDBでも、使われ方が違うとこうも構成が変わってくるんだな**というのが最大の発見でした。この設計思想の違いが理解できたことで、データ基盤の全体像が腹落ちしました。

---

### 苦労したポイントと気づき

#### bronze/silver/goldの境界が曖昧だが、本質は「段階的な加工」

データレイクのレイヤー分け（bronze/silver/gold）について学習しましたが、最初は**「どこまでがbronze、どこからがsilver」という明確な基準がない**ことに戸惑いました。

- **bronze（生データ）**: ここは比較的明確
- **silver（クレンジング済み）**: 「軽微な変換」ってどこまで？型変換だけ？NULL埋めも含む？
- **gold（分析用データ）**: ビジネスロジックを適用、とあるけど具体的には？

しかし、勉強していく中で気づいたのは、**大事なのは「3層に分ける」ことではなく、「段階的にデータを加工する」という考え方**だということです。

実際、プロジェクトによっては：

- シンプルに `raw` / `processed` の2層構成
- 細かく `raw` / `cleaned` / `enriched` / `mart` の4層構成

など、レイヤー数も定義も変わります。重要なのは以下の点：

1. **生データを保持する**（監査・検証のため変更不可で保存）
2. **段階的に加工する**（エラー時のデバッグや再利用がしやすい）
3. **最終的に分析用データを作る**（BIツールやMLモデルで使える形）

**明確な正解はなく、プロジェクトの要件に合わせて設計する**ものだと理解しました。このイメージを持っていれば、自分のプロジェクトでも構築していけると思います。

#### ETLが複数箇所で必要という意外性

ETL処理について調べていく中で、**ETLがデータパイプラインの複数箇所で必要になる**ことに驚きました。

1. **データソース → データレイク（bronze）**: 各種データソースからS3にデータを投入する際のETL
2. **bronze → silver → gold**: データレイク内での段階的な変換のためのETL

特に大規模プロジェクトでは、**一度S3を介してデータを保存し、さらに別のDB（DWH）にロードする**という「DB2個でやっていくイメージ」が意外でした。Webアプリでは「RDS1つ」で完結することが多いため、この多段階構成は新鮮でした。

---

### これから取り組む際に気をつけたいこと

#### 1. まずは概念の理解から始めたい

データ基盤を学習する中で、最初に躓きやすいと感じたのが「概念の理解」でした。

- **OLTP vs OLAP**: トランザクション処理と分析処理の違い
- **データレイク vs データウェアハウス**: 生データと構造化データの違い

**これまでやってこなかったリソースが多いので、改めて勉強が必要**だと感じました。Webアプリのインフラ経験があっても、データ基盤は別領域として学び直す必要がありそうです。

しかし、これらの基本概念を理解しておくと、各ツール（Athena、Redshift、Snowflake、Databricks）をどう使っていけば良いのか理解しやすくなりました。

#### 2. コスト監視は最初から設定したい

データ基盤は、Webアプリのインフラとはコスト構造が異なります。

- **Webアプリ**: インスタンスの稼働時間で課金
- **データ基盤**: データのスキャン量、DPU時間、ノード数で課金

特にAthenaは、パーティションを切らずに全データスキャンすると想定外のコストが発生します。ケアレスミスでコストが爆増しないためにも**最初からAWS Cost Explorerでアラートを設定しておく**のが大事だと感じました。

#### 3. 実際に手を動かして試したい

データ基盤は、**やってみないと理解が難しい**と感じました。

- ドキュメントを読むだけでは分からないことが多い
- 実際にAthenaでクエリを投げてみる、Glue ETLジョブを動かしてみる、という経験が重要
- PoC（概念実証）や小規模な検証環境で試してから本番構成を決めるのが良さそう

簡単に実践した方が理解が深まります。AWSの無料枠を使って試すのも良いと思います。
自分もやってみます！

#### 4. 選択肢の多さに惑わされないようにしたい

データ基盤には多くのツールがあり、最初は「どれを選べばいいのか」迷います。

- **AWSのツールのみで完結もできる**（Lambda + S3 + Athena + Redshift + Glue）
- **Snowflake/Databricksなどの専用ツールもある**（構成の多くをカバーしてくれる）

一度概念を理解していれば、どのツールを使っても基本は同じです。**自分のプロジェクトの要件（データ量、リアルタイム性、予算、社内のスキルセット）に合わせて選ぶ**のがポイントですね。

#### 5. ネット上の情報を積極的に活用したい

データエンジニアリングは近年注目されている分野なので、Qiita、Zenn、個人ブログなどに大量の記事があります。

- AWS公式ドキュメント（日本語対応）
- Snowflake/Databricksの公式チュートリアル
- dbtのドキュメント（実践的で分かりやすい）

同じような悩みを持った人の記事を探すと、解決策が見つかることが多いです。実際に今回の学習でも、多くの先人の記事に助けられました。

---

## 6. まとめ

この記事では、インフラエンジニアがデータ基盤を構築する際の基礎知識を学びました。

### 本記事で学んだこと

1. **データ基盤の全体像**: OLTP vs OLAP、データレイク vs データウェアハウス
2. **インフラ構成パターン**: 小規模（Lambda + S3 + Athena）、中規模（Glue + Redshift + dbt）、大規模（Kinesis + Databricks/Snowflake）
3. **データベース選定**: RDS、Aurora、Athena、Redshift の特徴と使い分け
4. **行指向vs列指向ストレージ**: データ量とクエリパターンに応じた選択基準

---

### 次回:【設計・ツール選定編】

次回は、データモデリングの詳細とツール選定を解説します：

- データモデリング詳説: スタースキーマ、ファクトテーブル、ディメンションテーブル
- ETL/ELT実装: AWS Glue、Lambda、Step Functions、dbt
- Snowflake vs Databricks: アーキテクチャ比較と選定基準

---
